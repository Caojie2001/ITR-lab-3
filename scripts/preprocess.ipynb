{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import py7zr\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def extract_md_files(archive_path, extract_to):\n",
    "    with py7zr.SevenZipFile(archive_path, 'r') as archive:\n",
    "        all_files = archive.getnames()\n",
    "        md_files = [f for f in all_files if f.endswith('.md')]\n",
    "        if md_files:\n",
    "            archive.extract(targets=md_files, path=extract_to)\n",
    "        else:\n",
    "            print(f\"No markdown files to extract in {archive_path}.\")\n",
    "\n",
    "def read_md_files_from_folder(folder_path):\n",
    "    md_contents = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.md'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    md_contents.append(file.read())\n",
    "    return md_contents\n",
    "\n",
    "folder_path = '/Users/caojie/Desktop/MACSS/2024 spring/Perspective3/rmrb-master/7z'\n",
    "extract_to = 'mediate'\n",
    "\n",
    "if not os.path.exists(extract_to):\n",
    "    os.makedirs(extract_to)\n",
    "\n",
    "data = []\n",
    "all_files = []\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.7z') and \"03月\" in file:\n",
    "            file_path = os.path.join(root, file)\n",
    "            all_files.append(file_path)\n",
    "\n",
    "for file_path in tqdm(all_files, desc=\"Processing .7z files\"):\n",
    "    extract_md_files(file_path, extract_to)\n",
    "    md_contents = read_md_files_from_folder(extract_to)\n",
    "    if md_contents:\n",
    "        for content in md_contents:\n",
    "            data.append({'filename': os.path.basename(file_path), 'content': content})\n",
    "    else:\n",
    "        print(f\"No Markdown files found in: {file_path}\")\n",
    "    shutil.rmtree(extract_to)\n",
    "    os.makedirs(extract_to)\n",
    "\n",
    "if not data:\n",
    "    print(\"No data extracted from any files.\")\n",
    "else:\n",
    "    print(f\"Extracted data from {len(data)} entries.\")\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "if df.empty:\n",
    "    print(\"DataFrame is empty.\")\n",
    "else:\n",
    "    print(\"DataFrame created successfully.\")\n",
    "    \n",
    "df.to_csv('rmrb_march.csv', index=False)\n",
    "shutil.rmtree(extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df['year'] = df['filename'].str.extract(r'(\\d{4})年')\n",
    "df['content'] = df['content'].apply(lambda x: ''.join(re.findall(r'[\\u4e00-\\u9fa5]', x)))\n",
    "df.drop('filename', axis=1, inplace=True)\n",
    "df = df[df['content'].str.contains('女', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = set()\n",
    "with open('/Users/caojie/Desktop/MACSS/2024 fall/data mining/week3/rmrb-master/baidu_stopwords.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        stopwords.add(line.strip())\n",
    "\n",
    "chinese_number_pattern = re.compile(r'[零一二两三四五六七八九十百千万亿]')\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: [\n",
    "    word for word in jieba.cut(x) \n",
    "    if word not in stopwords and len(word) > 1 and not chinese_number_pattern.search(word)\n",
    "])\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: ','.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['content'].tolist())\n",
    "sparse_matrix = csr_matrix(tfidf_matrix)\n",
    "np.savez_compressed(\"rmrb_march_tfidf_matrix.npz\", data=sparse_matrix.data, indices=sparse_matrix.indices, \n",
    "                    indptr=sparse_matrix.indptr, shape=sparse_matrix.shape)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
